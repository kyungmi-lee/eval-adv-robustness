# Rethinking Empirical Evaluation of Adversarial Robustness Using First-Order Attack Methods 
Kyungmi Lee & Anantha P. Chandrakasan <br/>
Department of Electrical Engineering & Computer Science, Massachusetts Institute of Technology <br/>
[`[arXiv]`](https://arxiv.org/abs/2006.01304)

## Summary
Measuring adversarial accuracy against samples generated by first-order attack methods became popular approach to empirically approximate adversarial robustness. Here, we examine bounded first-order attack methods, such as FGSM, R-FGSM, and PGD, on *when they fail to find adversarial examples* and *whether such failure indicates robustness*. We identify three cases where attack methods fail due to superficial reasons not implying robustness, thus result in inflated adversarial accuracy:
* Zero loss: loss on a sample can be close to zero, resulting in inaccurate computation of gradients due to limitied numerical precision
* Non-differentiability: neurons contributing to the final prediction can change between backward-pass for computing gradients and forward-pass for evaluating perturbations when non-differentiable functions, such as ReLU and max pooling, switch modes of neurons
* Require more iterations: certain training conditions seem to induce models to be less amenable to first-order approximations; then, iterative attacks using small fixed number of iterations can result in inflated accuracy

We present compensation methods for the above-mentioned three cases, and those methods can be easily combined with existing attack methods for more precise evaluation metric. Compensation methods combined with FGSM, R-FGSM, and PGD are included in `./compensated_attacks`, implemented based on AdverTorch. We benchmark how adversarial accuracy changes when compensating for the above-mentioned three cases for CIFAR-10, SVHN, and TinyImageNet datasets. Core codes shared among different experiments are in `./core`, and high-level codes with control arguments for experiments are located at this directory. Further explanations and experimental results are presented in the paper.

## Dependencies
Before using our code, please check following dependencies:
* PyTorch 1.0.1 (with CUDA version 10.0 & cuDNN 7.4)
* [AdverTorch](https://github.com/BorealisAI/advertorch): clone AdverTorch into this directory after cloning our repo. In case you directly install AdverTorch using pip, fix the relative path to AdverTorch accordingly for `./compensated_attacks`. 
* For TinyImageNet, download the dataset (https://tiny-imagenet.herokuapp.com/) and process such that PyTorch's ImageFolder can load data. Split validation set into half for validation and test set; test set supplied in the dataset itself does not contain labels. Fix the relative path to the folder containing TinyImageNet for `tinyimagenet_training.py` and `tinyimagenet_evaluate_all.py`.


<!---
## How to use
Example commands for running experiments are in `./code_run_script`. Note that example commands are not necessarily identical with experiments in the paper; those commands can be modified easily to replicate our experiments or run your experiments of interest. Here, we explain options for training and evaluating using our code. 
-->

<!---
### Training
Typical arguments for training codes (`cifar_training.py`, `svhn_training.py`, and `tinyimagenet_training.py`) are:

<!---
**Data loading**
* `seed`: manual random seed. Default: 0
* `train_batch_size`, `test_batch_size`: batch size for training and testing (on validation set if `train_val_split` is set True). Default: 128, 128
* `log_interval`: interval (number of iterations; not full epoch) for displaying training status and loss. Default: 200
* `train_val_split`: if set True, split 10% of train set for validation purpose. If early stopping is to be used, validation set should be utilized for evaluating the performance throughout training. Default: False

<!---
**Model architecture**
* `model_type`: base architecture of the model. Supports Simple and WideResNet architectures for CIFAR-10 and SVHN, and VGG-11 and WideResNet for TinyImageNet. 
* `scale_factor`: controlling the width of the model.
* `no_batch_norm` (for CIFAR-10 and SVHN) or `vgg_batch_norm` (TinyImageNet): controls the usage of Batch Normalization for Simple models (CIFAR-10 and SVHN) and VGG-11 (TiynImageNet).

<!---
**Optimization**
* `lr`: initial learning rate. Learning rate decay is implemented, such that the learning rate is decreased by factor of 10 every 40 epochs.
* `epochs`: total number of epochs.
* `optimizer`: type of optimizer to be used to train the model. Supports Stochastic Gradient Descent (`sgd`) and Adam (`adam`). Training for SVHN and TinyImageNet supports momentum (or $\beta_1$ of Adam) and $beta_2$ of Adam as arguments.
* `early_stop`, `early_stop_criteria`: if `early_stop` is set True, then the model with best accuracy in terms of `early_stop_criteria` will be saved.

<!---
**Adversarial training**
* `disable_adv`: disable adversarial training, and run conventional training on "clean" data when set True. Default: False
* `no_adv_eval`: don't evaluate on adversarial examples during training if set True. Use together with `disable_adv` for conventional training where evaluation of adversarial accuracy throughout training is unnecessary. Default: False
* `attack_type`, `eps`, `nb_iter`, `eps_iter`, `nb_random_start`, `l2pgd_init_method`: defines an attack to be used for adversarial training and evaluation. `attack_type` supports FGSM, R-FGSM, and PGD for both $L_\infty$ and $L_2$ norm, and C&W attack for $L_2$ norm. `eps` defines the maximum perturbation size, typically referred to $\epsilon$ in the literature. `nb_iter` defines the number of iterations for iterative attacks, such as PGD or C&W attack. `eps_iter` defines the step size for each iteration for PGD. `nb_random_start` defines the total number of random start in evaluation for attacks with stochasticity, such as R-FGSM or PGD. `l2pgd_init_method` defines the initialization methods to be used for PGD attacks; setting it to `rand` will be same as conventional PGD, and `miyato` and `bfgs` options refer to PGD + Eigen and PGD + BFGS, respectively. 

<!---
**Regularization options other than adversarial training**
* `weight_decay`: hyperparamter for the strength of weight decay. If set to zero, weight decay will not be used. Default: 5e-4
* `weight_decay_schedule`: if set True, increases the strength of weight decay every 40 epochs by the factor of 10 for excessive application of weight decay. The strength of weight decay at the start is decided by `weight_decay`.
* `spectral_norm`: if set True, uses Spectral Normalization after each convolutional and fully-connected layer (except for the final classifier).
* `orthonormal`: hyperparamter for the strength of orthonormal regularizaton. If set to zero, orthonormal regularization will not be used. Default: 0
* `jacobian`: hyperparameter for the strength of jacobian (or input-gradient) regularization. If set to zero, jacobian regularization will not be used. Default: 0

<!---
**Model and log saving/loading**
* `save_model`: directory and prefix for model saving. `save_model`+'full_train.pt' will save the model trained for full epochs, while `save_model`+'early_stop.pt' will save the model with best accuracy when early stopping is used. 
* `logs`: directory to save training log.
* `load_model`: directory for pre-trained model in case finetuning is to be used. In such case, this model's architecture should be defined using `model_type`, `scale_factor`, and `no_batch_norm` as mentioned above.

<!---
### Evaluating
Arguments for evaluation codes (`cifar_evalaute_all.py`, `svhn_evaluate_all.py`, `tinyimagenet_evalaute_all.py`) are similar to those for training codes. Specify data loading properties (random seed and batch size), and model information (path to the model checkpoint file, model type, width, and whether it uses batch norm or spectral norm), and the attack method of your interest (attack type--currently supporting bounded first-order methods, such as FGSM, R-FGSM, and PGD, epsilon, number of iterations, etc) as in training codes. Follwing options are unique to the evaluation, and they set compensation modes:

<!---
**Compensation methods: Zero loss**
* `zero_compensation`: default is set to none, which means zero compensation is not applied. Setting this argument to `temperature` will rescale logits by dividing them with the value specified for `temperature` argument (default: 100). Setting this argument to `targeted` will change the target label in the loss computation to the class specified in `targeted_to` argument (default: `random`).
* `temperature`: the value $T$ for rescaling logits.
* `targeted_to`: specifying the target class. `random` will randomly choose any class, `second` will choose the second most likely class predicted by the model, and `least-likely` will choose the least likely class predicted by the model.

<!---
**Compensation methods: Non-differentiability**
* `bpda_compensation`: default is set to False. Setting this to True will apply a compensation method for non-differentiability using BPDA, with specified arguments for `relu_sub`, `relu_sub_slope`, and `maxpool_sub_p` (see below).
* `relu_sub`: specifying which activation function to use for backward substitute of ReLU. Supports softplus, CELU, and ELU. 
* `relu_sub_slope`: slope parameter for activation functions used as substitute of ReLU. Only meaningful for softplus and CELU. ELU's slope parameter has to be fixed to $\alpah=1$ for differentiability at zero. 
* `maxpool_sub_p`: the value of $p$ for $L_p$ norm pooling used as a substitute for max pooling (only matter for architectures using max pooling). 

<!---
**Compensation methods: Require more iterations**
* `second_order_init_method`: sets the initialization method for PGD. Default is `rand`, which is the baseline PGD that initializes the perturbation as random values within the $\epsilon$-ball. For PGD + Eigen that initializes to the direction of the (approximated) principal eigenvector of Hessian, set this argument to `miyato` (referring to the paper that outlined core techniques used to approximate the principal eigenvector). For PGD + BFGS that initializes to the Quasi-Newton direction, set this argument to `BFGS`. When using PGD + BFGS, please be aware of the additional memory requirement incurred by storing Hessian matrix, and adjust the batch size. 

<!---
### Pruning
`cifar_pruning.py` is used for pruning experiments in the paper. Arguments for data loading, model information, optimization, and model saving/loading are similar to those for training codes. Following arguments are used to specify the pruning procedure:
* `prune`: indicator for whether pruning is applied. Default is set to False, and it has to be set to True for pruning. 
* `prune_method`: how to remove weights with small magnitudes. Setting to `global` will remove certain proportion of weights among all weight parameters across different layers, and setting to `layerwise` will remove certain proportion of weights from each layer (e.g. 25% per layer instead of 25% of all weights in the model). 
* `prune_all`: whether to prune fully connected layers as well. Default is set to False, and will only remove weights from convolution layers. Setting to True will remove weights from both convolution and fully connected layers. 
* `epochs`: number of pruning iterations, NOT the number of epochs for finetuning per iteration.
* `retrain_epochs`: number of epochs for finetuning per iteration.
* `prune_ratio`: specifies total proportion of weights to be removed at the end of pruning. When this is used with `prune_fixed_percent` set to False (see below), $(\frac{prune_ratio}{epochs}\times 100) %$ of weights will be removed each iteration.
* `prune_fixed_percent`: whether to prune fixed proportion of weights per iteration (e.g., remove 50% of remaining weights per iteration) instead of removing $(\frac{prune_ratio}{epochs}\times 100) %$ of weights as above. Default is set to False.
* `prune_ratio_per_step`: when `prune_fixed_percent` is True, indicates how many weights to KEEP per iteration (e.g. 0.75 will indicate keeping 75% of weights per iteration, in other words, removing 25% of weights remaining). 

